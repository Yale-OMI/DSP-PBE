\section{Metrical Synthesis}
\label{sec:opt}

In the metrical synthesis phase of the algorithm we tune the parameters of every \dspnode in the candidate filter structure.
To do this we use an adaption of stochastic gradient descent.
We cannot use gradient descent directly, as $\distFxn$ is not a differentiable function, because in our implementation we rely on file I/O.
Instead we calculate the derivative of \distFxn at a certain point by changing each parameter in the filter by small amount and recalculating the $\distFxn(\synthedFilter(i),o))$.
If the score improves from a small change, we estimate the rate of change and make larger adjustments to the parameter accordingly.
We additionally allow the user to set a maximum number of metrical attempts per structure, which corresponds to the number of steps we take in gradient descent for each structure before trying a new structure.
This is necessary to add as we do not have a guarantee that $\distFxn$ is a convex function, and thus gradient descent may not terminate in some cases.
