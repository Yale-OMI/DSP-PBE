\section{Introduction}

The great proliferation of computer music programming languages points to the difficulty of building a natural interface for users that want to computationally interact with musical data.
Programming applications in the domain of computer music, and specifically digital signal processing (DSP), requires that users not only grasp fundamental programming techniques, but also have a large domain specific knowledge on time and signal manipulations.
The amount of prerequisite skill and effort to overcome these barriers is often higher than many users are able to commit.

Furthermore, the difficult of programming DSP applications is often not commensurate with the creative intentions.
From a musical perspective, take the following simple use-case: 
Now the user wishes to apply this same effect to their own sample.
In order to recreate this effect on a new sample, the user will have to reprogram the filter from the scratch.
This process will involve writing code, testing the code, listening to the original example, and constantly tweaking parameter values.

Furthermore, the difficulty of programming DSP applications is often not commensurate with the creative intentions. 
As a motivating example, imagine a user hears a sample in a piece of music, and again hears the same sample later in the piece with some added effects.
In order to reuse this effect the user's own musical composition, the user must now reconstruct the filter that was used to transform an audio clip. 
In this case the user has the original audio file, and the transformed audio file, but does not know exactly how this transformation happened.
In the standard approach, a user would need to be a domain expert and listen to the two files, and aurally estimate which kinds of filters were used to achieve the transformation. 
Once the user has some suspicion as to the appropriate filter types that will be needed, the user must write a program in some language (SuperCollider~\cite{supercollider}, CSound~\cite{csound}, PureData~\cite{puredata} etc) to implement the DSP filter the user has in mind. 
Further still, the user will then need to spend time tweaking the filter parameters to find the best fit. 

%\subsection{DSP programming by example}

To simplify the user process, we introduce \textit{DSP programming by example} (DSP-PBE). With DSP-PBE, the user simply provides our tool with the original audio (input), and the transformed audio (output), and a DSP-PBE tool will automatically construct a DSP filter that approximates the transformation.

We formally define the problem of DSP programming by example as follows:
Given an input waveform $I$ and an output waveform $O$, construct a DSP filter $\synthFilter$, to minimize the aural distance $dist$ between the $O$ and $\synthFilter(I)$.
In a single line:
%
\begin{align*}
\text{Find } \synthFilter, \text{ such that } dist(O,\synthFilter(I))=0
\end{align*}


In the sequel we describe our approach to the two key components of this statement; the definition of distance, and a search technique to find $\synthFilter$.
A distance metric that is faithful to the psycho-acoustics of the human ear is critical for a useful DSP-PBE tool.
As an example, taking a trivial distance function that returns the difference in length of the two audio samples will allow a delay filter to satisfy any example pair of samples.
Additionally, an efficient search algorithm is critical, as the space of possible DSP filters is very large.
Not only do we need to consider a wide variety of filters, we need to consider the space of parameters for each filter, as well as the different ways of combining multiple filters.

