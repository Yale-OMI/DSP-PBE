\section{Evaluation}
\label{sec:eval}
\begin{table*}[!ht]
\centering
\setlength\tabcolsep{2em}
\begin{tabular}{|c | c | c | c |} 
 \hline
 Description & True DSP & Synth'ed DSP & Time (sec) \\ 
 \hline\hline
 Cartoon Spring & $lpf(800)  $ & $lpf(1989) $ & 56.195 \\
 Cartoon Spring & $lpf(5000) $ & $lpf(4000) \arrComp hpf(7000) $ & 54.004 \\
 Cartoon Spring & $hpf(1500) $ & $lpf(1000) \arrComp hpf(1000) $ & 53.964 \\
 BTS DNA (Kpop) & $lpf(2000) $ & $lpf(1996)	 $ & 56.874 \\
 Holst Mars     & $hpf(3500) $ & $lpf(10000) \arrComp hpf(1000)$  & 55.444 \\
 \hline
\end{tabular}
\caption{Time to converged on a solution DSP program for various benchmarks. The programs may not match the known DSP program, but may still be psycho-acoustically equivalent depending on the expertise of the listener. }
\label{table:eval}
\end{table*}

We implemented a DSP-PBE tool based on the approach described in Section~\ref{sec:distance} and Section~\ref{sec:search}.
Our tool is available open-source at~\url{www.github.com/santolucito/DSP-PBE}.
Our tool is mostly written in Haskell and uses the Vivid library~\cite{vivid} for bindings to SuperCollider~\cite{supercollider}.
Haskell allows easy access to type information and metaprogram construction tools that are useful for program synthesis, however the programs themselves are easily translated back to SuperCollider ``synth defs'', which are DSP filter programs.
We use the scipy python module for calling the FFT since the library is quite mature and provides a simplified interface specifically for calling FFT on audio.

One key implementation point is that we use a separate representation of a DSP for running gradient descent, and for actually processing the audio.
Gradient descent works best when all parameters are in the same scale, so we map the frequencies [0,20k] Hz to a [-1,1] scale.
Likewise, we map the application levels for each filter (how much of the filtered output should be included in the final mix) on a [-1,1] scale.

In Table~\ref{table:eval}, we show the results of running our tool on a set of benchmarks of input/output example audio samples.
The audio samples were transformed in Audacity, using the Low Pass Filter and High Pass Filter effects.
Since we use SuperCollider's filter implementations on the backend, there may be very slight variation, but this is to be expected in real-world application as well.
All experiments were run on an Intel Core i7-6820HQ CPU @ 2.70GHz with 16 GB of RAM and an Intel Sunrise Point-H HD Audio sound card.


We can also breakdown the runtime cost of synthesis into the two different stages - 1) initial program selection, and 2) gradient descent.
The initial program selection phase is a mostly fixed cost, as we always evaluate the same distribution of initial value.
On average this process takes roughly 40 seconds.
We outline future directions of research that may be able to reduce this cost in Section~\ref{sec:rtypes}.
